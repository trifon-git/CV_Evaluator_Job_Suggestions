name: Job Scraper Every 2 Hours

on:
  schedule:
    - cron: '0 */7 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-job-scraper:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install chromium
      
      - name: Create .env file
        run: |
          echo "MONGO_URI=${{ secrets.MONGO_URI }}" > .env
          echo "MONGO_DB_NAME=${{ secrets.MONGO_DB_NAME }}" >> .env
          echo "MONGO_COLLECTION=${{ secrets.MONGO_COLLECTION }}" >> .env
          echo "CHROMA_HOST=${{ secrets.CHROMA_HOST }}" >> .env
          echo "CHROMA_PORT=${{ secrets.CHROMA_PORT }}" >> .env
          echo "CHROMA_COLLECTION=${{ secrets.CHROMA_COLLECTION }}" >> .env
          echo "MODEL_NAME=${{ secrets.MODEL_NAME }}" >> .env
          # Add these lines for the custom LLM configuration
          echo "CUSTOM_LLM_API_URL=${{ secrets.CUSTOM_LLM_API_URL }}" >> .env
          echo "CUSTOM_LLM_MODEL_NAME=${{ secrets.CUSTOM_LLM_MODEL_NAME }}" >> .env
          # You can keep or remove OLLAMA/NGROK variables depending on whether [STEP3.5] still logs warnings about them
          # or if any other script might use them.
          # For [STEP3]llm_skill_extractor.py, they are no longer primary.
          echo "OLLAMA_API_URL=${{ secrets.OLLAMA_API_URL }}" >> .env
          echo "OLLAMA_MODEL_NAME=${{ secrets.OLLAMA_MODEL_NAME }}" >> .env
          echo "NGROK_API_URL=${{ secrets.NGROK_API_URL }}" >> .env
          echo "TOP_N_RESULTS=${{ secrets.TOP_N_RESULTS }}" >> .env
          echo "BATCH_SIZE=${{ secrets.BATCH_SIZE }}" >> .env
          echo "JOBINDEX_BASE_URL=${{ secrets.JOBINDEX_BASE_URL }}" >> .env
          echo "JOB_AGE_PARAM=${{ secrets.JOB_AGE_PARAM }}" >> .env
          echo "CV_FILE_PATH=${{ secrets.CV_FILE_PATH }}" >> .env
          echo "EMBEDDING_API_URL=${{ secrets.EMBEDDING_API_URL }}" >> .env
          echo "VERIFY_SSL=${{ secrets.VERIFY_SSL || 'true' }}" >> .env
          echo "MAX_CONCURRENT=10" >> .env
          echo "PAGE_TIMEOUT=10000" >> .env
      
      - name: Run Step 1 - Job Index Scraper
        run: |
          echo "Starting Step 1: Scraping job listings from JobIndex"
          python src/[STEP1]jobindex_scraper.py
          echo "Step 1 completed"
      
      - name: Run Step 2 - Get HTML Text
        run: |
          echo "Starting Step 2: Extracting HTML content from job listings"
          python src/[STEP2]get_html_text.py
          echo "Step 2 completed"

      - name: Run Step 3.5 - Extract and Store Skills
        run: |
          echo "Starting Step 3.5: Extracting and storing skills from job descriptions"
          python src/[STEP3.5]extract_store_skills.py
          echo "Step 3.5 completed"

      - name: Run Step 3 - Generate Embeddings
        run: |
          echo "Starting Step 3: Generating embeddings for job listings"
          python src/[STEP4]import_mongo_to_chroma.py
          echo "Step 3 completed"
      
      - name: Job Complete
        run: echo "Job scraper workflow completed successfully"